{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "LogisticRegressionData2.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3a0cdcbd880b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LogisticRegressionData2.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m118\u001b[0m \u001b[1;31m#total no. of datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    614\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[0;32m    615\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: LogisticRegressionData2.txt not found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data=np.loadtxt('LogisticRegressionData2.txt', delimiter=',') #dataset\n",
    "\n",
    "dataset=118 #total no. of datasets\n",
    "training_example=80 #no. of training examples used\n",
    "feature=2 #no. of features\n",
    "\n",
    "#making a function for feature scaling\n",
    "def feat_scale(X,training_example,feature):\n",
    "    Xmax=np.random.rand(training_example,feature)\n",
    "    for a in range(feature):\n",
    "        Xmax.T[a]=X.max(axis=0)[a]\n",
    "    Xmin=np.random.rand(training_example,feature)\n",
    "    for a in range(feature):\n",
    "        Xmin.T[a]=X.min(axis=0)[a]\n",
    "    Xmean=np.random.rand(training_example,feature)\n",
    "    for a in range(feature):\n",
    "        Xmean.T[a]=np.mean(X,axis=0)[a]\n",
    "    X=np.divide((X-Xmean),(Xmax-Xmin))\n",
    "    return X;\n",
    "\n",
    "#making the 'g' function\n",
    "def g_func(x):\n",
    "    g=1/(1+math.exp(-1*x))\n",
    "    return g;\n",
    "\n",
    "#making a function to carry out logistic regression problem and \n",
    "#giving accuracy of the program by entering the required details\n",
    "def logistic_reg_grad_descent(data,dataset,training_example,feature):\n",
    "    X=data[0:training_example,0:feature]\n",
    "    X=feat_scale(X,training_example,feature)\n",
    "    X=np.concatenate((np.ones((training_example,1)),X),axis=1) #because X0=1\n",
    "    Y=data[0:training_example,feature]\n",
    "    theta=np.random.rand(feature+1,1)*10\n",
    "    iteration=1000 #no. of iterations\n",
    "    alpha=1.5 #alpha value\n",
    "    #For iteration\n",
    "    theta1=theta #so that we can assign theta values simultaneously\n",
    "    for i in range(iteration):\n",
    "        for b in range(feature+1):\n",
    "             cost_func=0 #cost_func=differentiated cost function\n",
    "             for a in range(training_example):\n",
    "                 hypo=g_func(np.dot(X[a],theta))\n",
    "                 cost_func=cost_func+(hypo-Y[a])*X[a,b]\n",
    "             theta1[b]=theta[b]-alpha*s/training_example\n",
    "        theta=theta1\n",
    "    X1=data[training_example:,0:feature]\n",
    "    X1=feat_scale(X1,dataset-training_example,feature)\n",
    "    X1=np.concatenate((np.ones((dataset-training_example,1)),X1),axis=1) #because X0=1\n",
    "    Y1=data[training_example:,feature]\n",
    "    hypo=np.dot(X1,theta)\n",
    "    output=np.random.rand(dataset-training_example,1)\n",
    "    #Assuming that if 'g' function gives a value >=0.5 then output \n",
    "    #is 1 else output is 0\n",
    "    for a in range(dataset-training_example):\n",
    "        if hypo[a]>=0:\n",
    "            output[a]=1\n",
    "        else:\n",
    "            output[a]=0\n",
    "    #To calculate accuracy\n",
    "    accuracy=np.random.rand(dataset-training_example,1)\n",
    "    for k in range(dataset-training_example):\n",
    "        if Y1[k]==output[k]:\n",
    "            accuracy[k]=1\n",
    "        else:\n",
    "            accuracy[k]=0\n",
    "    accuracy=np.sum(accuracy)\n",
    "    accuracy=accuracy*100/(dataset-training_example)\n",
    "    return accuracy;\n",
    "\n",
    "\n",
    "accuracy=logistic_reg_grad_descent(data,m,n,n2)\n",
    "print('accuracy' ,accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
